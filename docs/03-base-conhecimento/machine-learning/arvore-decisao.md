# üå≥ √Årvore de Decis√£o (Decision Tree)

> **Status:** üü® Em revis√£o     
> **Tags:** #Supervisionado #Classificacao #Regressao #Interpretabilidade


---


## üìù O que √© o modelo?

A √Årvore de Decis√£o √© um algoritmo de aprendizado **supervisionado**, utilizado tanto para **classifica√ß√£o** quanto para **regress√£o**. Ele estrutura o processo de decis√£o em uma s√©rie de perguntas bin√°rias (sim/n√£o), criando uma estrutura hier√°rquica que se assemelha a um fluxograma.

## üí° Como funciona?

> No jogo **20 Perguntas**, para adivinhar um algo, voc√™ faz perguntas estrat√©gicas: "√â um animal?", "Ele voa?", "√â maior que uma bola de basquete?". Cada resposta elimina v√°rias possibilidades at√© que voc√™ chegue a um conjunto limitado de possibilidades, levando a uma decis√£o final.


### L√≥gica do modelo
O modelo funciona dividindo os dados repetidamente:
1. **N√≥ Raiz:** Escolhe a caracter√≠stica, ou *feature* que melhor divide os dados inicialmente, usando m√©tricas como *Gini* ou *Entropy*;
2. **Ramos:** S√£o os caminhos que os dados tomam dependendo da resposta √† pergunta;
3. **N√≥s Internos**: Pontos onde as decis√µes s√£o tomadas e os dados se distribuem;
4. **N√≥s Folha ou Folha:** S√£o os n√≥s finais que representam a previs√£o, a classe ou o valor num√©rico, decis√£o final;

!["√Årvore de Decis√£o"](https://cdn-wcsm.alura.com.br/2025/04/arvore-gif.gif)

### Classifica√ß√£o

Como mencionado no in√≠cio, os modelos de √°rvore de decis√£o podem ser utilizados tanto para **classifica√ß√£o** como tamb√©m para **regress√£o**. Nos modelos de classifica√£o a inten√ß√£o √© agrupar dados em classes diferentes ou conjuntos predefinidos.

### Regress√£o

Nas √°rvores de regress√£o, o objetivo √© prever valores num√©ricos, ou seja, pre√ßos, temperatura, quantidade, etc., que podem variar em um intervalo.


## ‚öô Principais Hiperpar√¢metros

Os hiperpar√¢metros s√£o configura√ß√µes de um modelo que podem alterar seu desempenho e efic√°cia. Diferente dos par√¢metros do modelo, que s√£o ajustados automaticamente durante o treinamento, os hiperpar√¢metros devem ser definidos antes do processo de aprendizado.

Hiperpar√¢metros mal ajustados podem levar a problemas como overfitting, onde o modelo se ajusta excessivamente aos dados de treinamento, ou underfitting, onde o modelo n√£o consegue capturar a complexidade dos dados.

Estes s√£o os par√¢metros de controle, que evitam que a √°rvore cres√ßa demais ou memorize os dados de treino:

| Hiperpar√¢metro | Fun√ß√£o | Impacto |
| :--- | :--- | :--- |
| `max_depth` | Profundidade m√°xima da √°rvore. | ‚¨ÜÔ∏è Mais complexidade, aumentando o risco de Overfitting. |
| `min_samples_split` | M√≠nimo de amostras para criar uma nova divis√£o. | ‚¨áÔ∏è Divis√µes mais espec√≠ficas, maior risco de Overfitting. |
| `min_samples_leaf` | M√≠nimo de amostras que uma "folha" deve ter. | ‚¨ÜÔ∏è Suaviza o modelo, evita folhas com apenas 1 dado. |
| `criterion` | Fun√ß√£o que mede a qualidade da divis√£o. | Op√ß√£o de `gini`, para ser mais r√°pido, ou `entropy`, para ser mais rigoroso |

## ‚ö†Ô∏è Aten√ß√£o aos erros de principiante!
* **A √°rvore "infinita":** Estabele√ßa um limite para o crescimento da √°rvore, defina um `max_depth`. Isso garante que ela aprenda padr√µes e n√£o ru√≠dos;

* **Dados desbalanceados:** Se voc√™ tem 90% de uma classe e 10% de outra, a √°rvore pode simplesmente ignorar a minorit√°ria. Devido a isso recomenda-se o uso de `class_weight='balanced'`;

* **Vari√°veis com muitas categorias:** Colunas tipo "ID", nomes ou c√≥digos √∫nicos devem ser evitados, pois √© provavel que a √°rvore tente criar um ramo para cada um desses valores;

## üìà Vantagens & Limita√ß√µes

| ‚úÖ Vantagens | ‚ùå Limita√ß√µes |
|:--- | :--- |
| **Alta interpretabilidade:** √â f√°cil explicar por que o modelo tomou certa decis√£o | **Instabilidade:** Pequenas mudan√ßas nos dados podem gerar uma √°rvore completamente diferente |
| **Sem pr√©-processamento:** N√£o exige normaliza√ß√£o ou padroniza√ß√£o de escalas dos dados | **Overfitting:** Se n√£o for limitada, a √°rvore tentar√° memorizar o dataset de treino, n√£o conseguindo prever padr√µes n√£o aprendidos |
| **Suporta diversos tipos de dados:** Aceita vari√°veis num√©ricas e categ√≥ricas simultaneamente | **Vi√©s de classe:** Caso os dados estejam desbalanceados, tende a favorecer a classe majorit√°ria |


## üß© Quando usar?
* **Baselines R√°pidos:** Para come√ßar um projeto e entender quais vari√°veis s√£o mais importantes;

* **Transpar√™ncia Requerida:** Projetos onde o usu√°rio final precise entender a l√≥gica por tr√°s da IA;


### üìã Aplica√ß√µes

* **Detec√ß√£o de Fraude:** O algoritmo pode analisar transa√ß√µes, valores, localiza√ß√£o, hist√≥rico do cliente, etc. e classificar as transa√ß√µes com "fradulentas" ou "n√£o fraudulentas";

* **Aprova√ß√£o de Cr√©dito:** Definir se um cliente √© "bom pagador" com base nos dados dispon√≠veis desse cliente, renda, hist√≥rico de atrasos em pagamentos, ades√£o √† programas de fidelidade do banco;

* **Diagn√≥stico M√©dico:** √Årvores de decis√£o baseadas em sintomas do paciente, como: Febre? Tosse? Manchas na pele? Falta de ar? etc., ajudam a limitar quais as patologias provaveis do paciente;


## üéÆ Implementa√ß√£o R√°pida (Python)
```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

# Inicializando o modelo com limite de profundidade
model = DecisionTreeClassifier(max_depth=5, random_state=42)

# Treino e Predi√ß√£o
model.fit(X_train, y_train)
previsoes = model.predict(X_test)

# Dica: Visualize a √°rvore gerada
# from sklearn.tree import plot_tree
# plot_tree(model)
```


## üîó Refer√™ncias e Links Adicionais
- [Documenta√ß√£o Oficial Scikit-Learn (Trees)](https://scikit-learn.org/stable/modules/tree.html)